### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution
	 Mode 2: (1stPSAM,)
		0thBoundUnsaturatedRound→Aggregate→2ndContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-0.0021, -0.1315, -0.0539, -0.1221,  0.0037, -0.0889,  0.0864,  0.0523,
			                 0.0677, -0.1044, -0.0155, -0.1560,  0.1764,  0.1331,  0.1319,  0.0522,
			                 0.0089, -0.0983, -0.0030, -0.0968,  0.1252, -0.0878, -0.1092, -0.0577,
			                -0.0903, -0.1113,  0.1633,  0.0636,  0.1688, -0.0751, -0.0794, -0.0634])
			Loss decreased
			Epoch 0 took 0.02s NLL: 1.2781313658 Reg.: 0.0008411132 Distance: 0.6525290012 Patience: 10
			Epoch 1 took 0.01s NLL: 1.2781313658 Reg.: 0.0008411132 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.7319705486297607
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-0.0021, -0.1315, -0.0539, -0.1221,  0.0037, -0.0889,  0.0864,  0.0523,
			                 0.0677, -0.1044, -0.0155, -0.1560,  0.1764,  0.1331,  0.1319,  0.0522,
			                 0.0089, -0.0983, -0.0030, -0.0968,  0.1252, -0.0878, -0.1092, -0.0577,
			                -0.0903, -0.1113,  0.1633,  0.0636,  0.1688, -0.0751, -0.0794, -0.0634]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-0.0021, -0.1315, -0.0539, -0.1221,  0.0037, -0.0889,  0.0864,  0.0523,
			                 0.0677, -0.1044, -0.0155, -0.1560,  0.1764,  0.1331,  0.1319,  0.0522,
			                 0.0089, -0.0983, -0.0030, -0.0968,  0.1252, -0.0878, -0.1092, -0.0577,
			                -0.0903, -0.1113,  0.1633,  0.0636,  0.1688, -0.0751, -0.0794, -0.0634])
			Loss decreased
			Epoch 0 took 0.22s NLL: 3.8462691307 Reg.: 0.0004696041 Distance: 22.6225967407 Patience: 10
			Epoch 1 took 0.31s NLL: nan Reg.: 0.0000216247 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-0.0021, -0.1315, -0.0539, -0.1221,  0.0037, -0.0889,  0.0864,  0.0523,
			                 0.0677, -0.1044, -0.0155, -0.1560,  0.1764,  0.1331,  0.1319,  0.0522,
			                 0.0089, -0.0983, -0.0030, -0.0968,  0.1252, -0.0878, -0.1092, -0.0577,
			                -0.0903, -0.1113,  0.1633,  0.0636,  0.1688, -0.0751, -0.0794, -0.0634])
			Epoch 0 took 0.22s NLL: nan Reg.: 0.0000216247 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-3.6915, -4.4044, -4.2118, -3.9478, -7.3760,  5.3194, -6.6959, -7.5030,
			                 2.8770, -6.1147, -6.2405, -6.7773, -4.0393, -3.4865, -4.9469, -3.7828])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-0.0021, -0.1315, -0.0539, -0.1221,  0.0037, -0.0889,  0.0864,  0.0523,
			                 0.0677, -0.1044, -0.0155, -0.1560,  0.1764,  0.1331,  0.1319,  0.0522,
			                 0.0089, -0.0983, -0.0030, -0.0968,  0.1252, -0.0878, -0.1092, -0.0577,
			                -0.0903, -0.1113,  0.1633,  0.0636,  0.1688, -0.0751, -0.0794, -0.0634]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-3.6915, -4.4044, -4.2118, -3.9478, -7.3760,  5.3194, -6.6959, -7.5030,
			                 2.8770, -6.1147, -6.2405, -6.7773, -4.0393, -3.4865, -4.9469, -3.7828])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-0.0021, -0.1315, -0.0539, -0.1221,  0.0037, -0.0889,  0.0864,  0.0523,
			                 0.0677, -0.1044, -0.0155, -0.1560,  0.1764,  0.1331,  0.1319,  0.0522,
			                 0.0089, -0.0983, -0.0030, -0.0968,  0.1252, -0.0878, -0.1092, -0.0577,
			                -0.0903, -0.1113,  0.1633,  0.0636,  0.1688, -0.0751, -0.0794, -0.0634])
			Loss decreased
			Epoch 0 took 0.19s NLL: 1.2757314444 Reg.: 0.0004535116 Distance: 2.4621934891 Patience: 10
			Loss decreased
			Epoch 1 took 0.12s NLL: 1.2756842375 Reg.: 0.0003800607 Distance: 5.3148036003 Patience: 10
			Loss decreased
			Epoch 2 took 0.09s NLL: 1.2756708860 Reg.: 0.0003639949 Distance: 3.1344385147 Patience: 10
			Loss decreased
			Epoch 3 took 0.29s NLL: 1.2700772285 Reg.: 0.0000521401 Distance: 13.8932561874 Patience: 10
			Epoch 4 took 0.13s NLL: 1.2700772285 Reg.: 0.0000521401 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.7393271923065186
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -0.8757545351982117
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-0.5258, -2.3080, -1.1662, -0.8196, -1.2398, -0.6232, -1.8380, -1.1186,
			                 2.1520, -1.9041, -2.4036, -2.6640, -1.8222, -0.0903, -2.0360, -0.8711])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-0.0021, -0.1315, -0.0539, -0.1221,  0.0037, -0.0889,  0.0864,  0.0523,
			                 0.0677, -0.1044, -0.0155, -0.1560,  0.1764,  0.1331,  0.1319,  0.0522,
			                 0.0089, -0.0983, -0.0030, -0.0968,  0.1252, -0.0878, -0.1092, -0.0577,
			                -0.0903, -0.1113,  0.1633,  0.0636,  0.1688, -0.0751, -0.0794, -0.0634]) 


### Training Mode 2: 1stPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→2ndContribution → 0thBoundUnsaturatedRound→1stPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→2ndContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	1stPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.3487653732299805
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -2.48519229888916
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -1.4978094100952148
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-0.5258, -2.3080, -1.1662, -0.8196, -1.2398, -0.6232, -1.8380, -1.1186,
			                 2.1520, -1.9041, -2.4036, -2.6640, -1.8222, -0.0903, -2.0360, -0.8711])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-0.0021, -0.1315, -0.0539, -0.1221,  0.0037, -0.0889,  0.0864,  0.0523,
			                 0.0677, -0.1044, -0.0155, -0.1560,  0.1764,  0.1331,  0.1319,  0.0522,
			                 0.0089, -0.0983, -0.0030, -0.0968,  0.1252, -0.0878, -0.1092, -0.0577,
			                -0.0903, -0.1113,  0.1633,  0.0636,  0.1688, -0.0751, -0.0794, -0.0634])
			Loss decreased
			Epoch 0 took 0.25s NLL: 1.0679291487 Reg.: 0.0000737670 Distance: 1.5812684298 Patience: 10
			Loss decreased
			Epoch 1 took 0.27s NLL: 1.0677680969 Reg.: 0.0000738673 Distance: 0.4144704342 Patience: 10
			Epoch 2 took 0.10s NLL: 1.0677680969 Reg.: 0.0000738673 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.3487653732299805
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -2.48519229888916
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -1.4978094100952148
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-0.5258, -2.3080, -1.1662, -0.8196, -1.2398, -0.6232, -1.8380, -1.1186,
			                 2.1520, -1.9041, -2.4036, -2.6640, -1.8222, -0.0903, -2.0360, -0.8711])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.1664, -0.5393, -0.2316,  0.0359,  0.0138, -0.2163, -0.3891,  0.3854,
			                 0.2741, -0.6252, -0.1421,  0.0259,  0.1937, -0.2479, -0.1519,  0.4391,
			                 0.0295, -0.3841, -0.3738,  0.2799,  0.3244, -0.6272, -0.0777, -0.0083,
			                -0.0294, -0.2186, -0.3632,  0.3768,  0.1953, -0.4315, -0.1770,  0.1047]) 

	2.	0thBoundUnsaturatedRound→1stPSAMMode.update_read_length(left_shift=1, right_shift=1)
	Greedy search terminated: left flank length of 1 exceeds max_left_flank_length of 0
	3.	1stPSAM.shift_heuristic()
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.3487653732299805
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -2.48519229888916
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -1.4978094100952148
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-0.5258, -2.3080, -1.1662, -0.8196, -1.2398, -0.6232, -1.8380, -1.1186,
			                 2.1520, -1.9041, -2.4036, -2.6640, -1.8222, -0.0903, -2.0360, -0.8711])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.1664, -0.5393, -0.2316,  0.0359,  0.0138, -0.2163, -0.3891,  0.3854,
			                 0.2741, -0.6252, -0.1421,  0.0259,  0.1937, -0.2479, -0.1519,  0.4391,
			                 0.0295, -0.3841, -0.3738,  0.2799,  0.3244, -0.6272, -0.0777, -0.0083,
			                -0.0294, -0.2186, -0.3632,  0.3768,  0.1953, -0.4315, -0.1770,  0.1047])
			Epoch 0 took 0.02s NLL: 1.0677680969 Reg.: 0.0000738673 Distance: 0.0001062279 Patience: 9
			Epoch 1 took 0.02s NLL: 1.0677680969 Reg.: 0.0000738672 Distance: 0.0001614019 Patience: 8
			Epoch 2 took 0.03s NLL: 1.0677680969 Reg.: 0.0000738667 Distance: 0.0008557151 Patience: 7
			Epoch 3 took 0.03s NLL: 1.0677680969 Reg.: 0.0000738662 Distance: 0.0009391975 Patience: 6
			Epoch 4 took 0.03s NLL: 1.0677680969 Reg.: 0.0000738659 Distance: 0.0005410361 Patience: 5
			Epoch 5 took 0.03s NLL: 1.0677680969 Reg.: 0.0000738660 Distance: 0.0000762996 Patience: 4
			Epoch 6 took 0.03s NLL: 1.0677680969 Reg.: 0.0000738660 Distance: 0.0001719587 Patience: 3
			Epoch 7 took 0.03s NLL: 1.0677680969 Reg.: 0.0000738659 Distance: 0.0003914835 Patience: 2
			Loss decreased
			Epoch 8 took 0.08s NLL: 1.0677679777 Reg.: 0.0000738658 Distance: 0.0003805637 Patience: 10
			Epoch 9 took 0.07s NLL: 1.0677679777 Reg.: 0.0000738658 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.3487653732299805
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -2.48519229888916
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -1.4978094100952148
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-0.5258, -2.3080, -1.1662, -0.8196, -1.2398, -0.6232, -1.8380, -1.1186,
			                 2.1520, -1.9041, -2.4036, -2.6640, -1.8222, -0.0903, -2.0360, -0.8711])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.1669, -0.5395, -0.2321,  0.0362,  0.0134, -0.2154, -0.3895,  0.3853,
			                 0.2742, -0.6250, -0.1429,  0.0265,  0.1934, -0.2483, -0.1514,  0.4392,
			                 0.0295, -0.3846, -0.3734,  0.2802,  0.3237, -0.6258, -0.0780, -0.0087,
			                -0.0291, -0.2182, -0.3641,  0.3770,  0.1950, -0.4308, -0.1768,  0.1041]) 

	Update rejected
	4.	1stPSAM.update_footprint(left_shift=1, check_threshold=True, right_shift=1)
	Greedy search terminated: Cannot shift footprint ((0, 0)) since information content is [0.04824066162109375, 0.0637589693069458] on the left and [0.04059934616088867, 0.06023573875427246] on the right; 0.1 needed for shift
	5.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -4.3487653732299805
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -2.48519229888916
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=True -1.4978094100952148
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-0.5258, -2.3080, -1.1662, -0.8196, -1.2398, -0.6232, -1.8380, -1.1186,
			                 2.1520, -1.9041, -2.4036, -2.6640, -1.8222, -0.0903, -2.0360, -0.8711])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.1664, -0.5393, -0.2316,  0.0359,  0.0138, -0.2163, -0.3891,  0.3854,
			                 0.2741, -0.6252, -0.1421,  0.0259,  0.1937, -0.2479, -0.1519,  0.4391,
			                 0.0295, -0.3841, -0.3738,  0.2799,  0.3244, -0.6272, -0.0777, -0.0083,
			                -0.0294, -0.2186, -0.3632,  0.3768,  0.1953, -0.4315, -0.1770,  0.1047])
			Loss decreased
			Epoch 0 took 0.30s NLL: 1.0628039837 Reg.: 0.0000746918 Distance: 1.7801975012 Patience: 10
			Loss decreased
			Epoch 1 took 0.29s NLL: 1.0622019768 Reg.: 0.0000702365 Distance: 0.8754758835 Patience: 10
			Loss decreased
			Epoch 2 took 0.57s NLL: 1.0579355955 Reg.: 0.0000476829 Distance: 2.9220490456 Patience: 10
			Loss decreased
			Epoch 3 took 0.74s NLL: 1.0561071634 Reg.: 0.0000397797 Distance: 1.4786204100 Patience: 10
			Loss decreased
			Epoch 4 took 0.46s NLL: 1.0530933142 Reg.: 0.0000339690 Distance: 1.9375333786 Patience: 10
			Loss decreased
			Epoch 5 took 0.38s NLL: 1.0523706675 Reg.: 0.0000329105 Distance: 0.5912050009 Patience: 10
			Loss decreased
			Epoch 6 took 0.32s NLL: 1.0523041487 Reg.: 0.0000328860 Distance: 0.2943142354 Patience: 10
			Epoch 7 took 0.04s NLL: 1.0523041487 Reg.: 0.0000328867 Distance: 0.0008514004 Patience: 9
			Loss decreased
			Epoch 8 took 0.08s NLL: 1.0523039103 Reg.: 0.0000328931 Distance: 0.0031633070 Patience: 10
			Epoch 9 took 0.06s NLL: 1.0523039103 Reg.: 0.0000328964 Distance: 0.0006432307 Patience: 9
			Epoch 10 took 0.05s NLL: 1.0523039103 Reg.: 0.0000328975 Distance: 0.0004287029 Patience: 8
			Epoch 11 took 0.04s NLL: 1.0523039103 Reg.: 0.0000328990 Distance: 0.0005221782 Patience: 7
			Epoch 12 took 0.04s NLL: 1.0523039103 Reg.: 0.0000328992 Distance: 0.0004851200 Patience: 6
			Epoch 13 took 0.04s NLL: 1.0523039103 Reg.: 0.0000328986 Distance: 0.0001785411 Patience: 5
			Epoch 14 took 0.02s NLL: 1.0523039103 Reg.: 0.0000328986 Distance: 0.0000000000 Patience: 4
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -4.490450382232666
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -0.6447457671165466
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=True -1.7596102952957153
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.0675, -0.6318, -0.4181, -0.1617, -0.1878, -0.3194, -0.7555,  0.1186,
			                 0.2609, -0.8489, -0.2925, -0.2636, -0.2169, -0.3067, -0.7889,  0.1684])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-0.0382, -0.4559, -0.3678, -0.0021,  0.0697, -0.4126, -0.3200,  0.1484,
			                 0.1736, -0.5491, -0.2336, -0.1572,  0.2689, -0.4095, -0.1500,  0.1992,
			                -0.2153, -0.1299, -0.7808,  0.3780,  0.8442, -1.2672,  0.3720, -0.6397,
			                -0.2271, -0.0906, -0.6532,  0.4291,  0.2331, -0.5832, -0.2201, -0.0430]) 

### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.02s NLL: 1.2781313658 Reg.: 0.0008407974 Distance: 0.6525290012 Patience: 10
			Epoch 1 took 0.01s NLL: 1.2781313658 Reg.: 0.0008407974 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.7319705486297607
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.23s NLL: 3.8462691307 Reg.: 0.0004692884 Distance: 22.6225967407 Patience: 10
			Epoch 1 took 0.24s NLL: nan Reg.: 0.0000213090 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.18s NLL: nan Reg.: 0.0000213090 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-3.6915, -4.4044, -4.2118, -3.9478, -7.3760,  5.3194, -6.6959, -7.5030,
			                 2.8770, -6.1147, -6.2405, -6.7773, -4.0393, -3.4865, -4.9469, -3.7828]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-3.6915, -4.4044, -4.2118, -3.9478, -7.3760,  5.3194, -6.6959, -7.5030,
			                 2.8770, -6.1147, -6.2405, -6.7773, -4.0393, -3.4865, -4.9469, -3.7828])
			Loss decreased
			Epoch 0 took 0.18s NLL: 1.2757314444 Reg.: 0.0004531959 Distance: 2.4621934891 Patience: 10
			Loss decreased
			Epoch 1 took 0.12s NLL: 1.2756842375 Reg.: 0.0003797450 Distance: 5.3148036003 Patience: 10
			Loss decreased
			Epoch 2 took 0.11s NLL: 1.2756708860 Reg.: 0.0003636792 Distance: 3.1344385147 Patience: 10
			Epoch 3 took 0.35s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True nan
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True nan
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.21s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.7344460487365723
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.764986276626587
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-2.8543e+00, -3.9880e+00, -3.5624e+00, -3.2037e+00, -5.6610e+00,
			                 2.9578e+00, -5.1486e+00, -5.7566e+00,  1.1758e+00, -4.7133e+00,
			                -4.8278e+00, -5.2431e+00, -1.6066e+00, -1.1197e-02, -1.1323e+01,
			                -6.6734e-01]) 

### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.03s NLL: 1.2781313658 Reg.: 0.0008407974 Distance: 0.6525290012 Patience: 10
			Epoch 1 took 0.01s NLL: 1.2781313658 Reg.: 0.0008407974 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.7319705486297607
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.21s NLL: 3.8462691307 Reg.: 0.0004692884 Distance: 22.6225967407 Patience: 10
			Epoch 1 took 0.25s NLL: nan Reg.: 0.0000213090 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.20s NLL: nan Reg.: 0.0000213090 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-3.6915, -4.4044, -4.2118, -3.9478, -7.3760,  5.3194, -6.6959, -7.5030,
			                 2.8770, -6.1147, -6.2405, -6.7773, -4.0393, -3.4865, -4.9469, -3.7828]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-3.6915, -4.4044, -4.2118, -3.9478, -7.3760,  5.3194, -6.6959, -7.5030,
			                 2.8770, -6.1147, -6.2405, -6.7773, -4.0393, -3.4865, -4.9469, -3.7828])
			Loss decreased
			Epoch 0 took 0.24s NLL: 1.2757314444 Reg.: 0.0004531959 Distance: 2.4621934891 Patience: 10
			Loss decreased
			Epoch 1 took 0.35s NLL: 1.2756842375 Reg.: 0.0003797450 Distance: 5.3148036003 Patience: 10
			Loss decreased
			Epoch 2 took 0.32s NLL: 1.2756708860 Reg.: 0.0003636792 Distance: 3.1344385147 Patience: 10
			Epoch 3 took 0.65s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True nan
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True nan
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.26s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.7344460487365723
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.764986276626587
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-2.8543e+00, -3.9880e+00, -3.5624e+00, -3.2037e+00, -5.6610e+00,
			                 2.9578e+00, -5.1486e+00, -5.7566e+00,  1.1758e+00, -4.7133e+00,
			                -4.8278e+00, -5.2431e+00, -1.6066e+00, -1.1197e-02, -1.1323e+01,
			                -6.6734e-01]) 

### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.02s NLL: 1.2781313658 Reg.: 0.0008407974 Distance: 0.6525290012 Patience: 10
			Epoch 1 took 0.01s NLL: 1.2781313658 Reg.: 0.0008407974 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.7319705486297607
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.18s NLL: 3.8462691307 Reg.: 0.0004692884 Distance: 22.6225967407 Patience: 10
			Epoch 1 took 0.22s NLL: nan Reg.: 0.0000213090 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.19s NLL: nan Reg.: 0.0000213090 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-3.6915, -4.4044, -4.2118, -3.9478, -7.3760,  5.3194, -6.6959, -7.5030,
			                 2.8770, -6.1147, -6.2405, -6.7773, -4.0393, -3.4865, -4.9469, -3.7828]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.5688190460205078
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-3.6915, -4.4044, -4.2118, -3.9478, -7.3760,  5.3194, -6.6959, -7.5030,
			                 2.8770, -6.1147, -6.2405, -6.7773, -4.0393, -3.4865, -4.9469, -3.7828])
			Loss decreased
			Epoch 0 took 0.17s NLL: 1.2757314444 Reg.: 0.0004531959 Distance: 2.4621934891 Patience: 10
			Loss decreased
			Epoch 1 took 0.11s NLL: 1.2756842375 Reg.: 0.0003797450 Distance: 5.3148036003 Patience: 10
			Loss decreased
			Epoch 2 took 0.08s NLL: 1.2756708860 Reg.: 0.0003636792 Distance: 3.1344385147 Patience: 10
			Epoch 3 took 0.30s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True nan
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True nan
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.18s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.7344460487365723
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.764986276626587
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-2.8543e+00, -3.9880e+00, -3.5624e+00, -3.2037e+00, -5.6610e+00,
			                 2.9578e+00, -5.1486e+00, -5.7566e+00,  1.1758e+00, -4.7133e+00,
			                -4.8278e+00, -5.2431e+00, -1.6066e+00, -1.1197e-02, -1.1323e+01,
			                -6.6734e-01]) 

### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-6.8041, 20.4124, -6.8041, -6.8041, 20.4124, -6.8041, -6.8041, -6.8041,
			                 0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.02s NLL: 1.2781313658 Reg.: 0.0011185807 Distance: 0.6525290012 Patience: 10
			Epoch 1 took 0.00s NLL: 1.2781313658 Reg.: 0.0011185807 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.7319705486297607
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-6.8041, 20.4124, -6.8041, -6.8041, 20.4124, -6.8041, -6.8041, -6.8041,
			                 0.0000,  0.0000,  0.0000,  0.0000]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -2.6674320697784424
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-6.8041, 20.4124, -6.8041, -6.8041, 20.4124, -6.8041, -6.8041, -6.8041,
			                 0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.17s NLL: 3.8086757660 Reg.: 0.0006001991 Distance: 27.2674827576 Patience: 10
			Loss decreased
			Epoch 1 took 0.14s NLL: 3.7091948986 Reg.: 0.0001286002 Distance: 15.3487005234 Patience: 10
			Epoch 2 took 0.08s NLL: 3.7091948986 Reg.: 0.0001286002 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -2.6674320697784424
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-4.0749,  4.0192, -3.6729, -4.3941, -1.3916, -1.7934, -1.8485, -3.0892,
			                -1.8460, -1.0356, -3.2337, -2.0074]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -4.341407775878906
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -2.6674320697784424
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-4.0749,  4.0192, -3.6729, -4.3941, -1.3916, -1.7934, -1.8485, -3.0892,
			                -1.8460, -1.0356, -3.2337, -2.0074])
			Loss decreased
			Epoch 0 took 0.17s NLL: 1.2732131481 Reg.: 0.0001781482 Distance: 7.1093049049 Patience: 10
			Loss decreased
			Epoch 1 took 0.19s NLL: 1.2487142086 Reg.: 0.0004082362 Distance: 9.5378999710 Patience: 10
			Loss decreased
			Epoch 2 took 0.18s NLL: 1.2350165844 Reg.: 0.0002966517 Distance: 4.3781232834 Patience: 10
			Loss decreased
			Epoch 3 took 0.18s NLL: 1.2332037687 Reg.: 0.0002039874 Distance: 3.9847688675 Patience: 10
			Loss decreased
			Epoch 4 took 0.20s NLL: 1.2091680765 Reg.: 0.0000244841 Distance: 10.6494073868 Patience: 10
			Loss decreased
			Epoch 5 took 0.21s NLL: 1.1207230091 Reg.: 0.0000237868 Distance: 3.3629577160 Patience: 10
			Loss decreased
			Epoch 6 took 0.19s NLL: 1.0942049026 Reg.: 0.0000240488 Distance: 2.1031494141 Patience: 10
			Loss decreased
			Epoch 7 took 0.10s NLL: 1.0940787792 Reg.: 0.0000250889 Distance: 0.1643942446 Patience: 10
			Epoch 8 took 0.01s NLL: 1.0940787792 Reg.: 0.0000250889 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -4.543989181518555
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True 0.03331751376390457
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-0.0430, -1.0087, -0.9336, -0.0956, -0.3611, -0.6494, -0.7913, -0.2801,
			                -0.2529, -0.7809, -0.6979, -0.3496]) 

