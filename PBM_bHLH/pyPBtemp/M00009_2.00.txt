### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution
	 Mode 2: (1stPSAM,)
		0thBoundUnsaturatedRound→Aggregate→2ndContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0651, -0.0683,  0.1758,  0.0612,  0.1008,  0.0521,  0.1378, -0.1505,
			                 0.1099, -0.0088,  0.1262, -0.0772, -0.1273, -0.0341,  0.1340, -0.0919,
			                 0.1005,  0.1687,  0.0555,  0.0395,  0.1722, -0.1073,  0.0085, -0.1426,
			                -0.0166, -0.0825,  0.0667, -0.1364,  0.1725, -0.0275,  0.0604,  0.1058])
			Loss decreased
			Epoch 0 took 0.14s NLL: 2.3551154137 Reg.: 0.0008386591 Distance: 0.1497137547 Patience: 10
			Epoch 1 took 0.01s NLL: 2.3551154137 Reg.: 0.0008386591 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.2291553020477295
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0651, -0.0683,  0.1758,  0.0612,  0.1008,  0.0521,  0.1378, -0.1505,
			                 0.1099, -0.0088,  0.1262, -0.0772, -0.1273, -0.0341,  0.1340, -0.0919,
			                 0.1005,  0.1687,  0.0555,  0.0395,  0.1722, -0.1073,  0.0085, -0.1426,
			                -0.0166, -0.0825,  0.0667, -0.1364,  0.1725, -0.0275,  0.0604,  0.1058]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592767715454
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.0660037994384766
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0651, -0.0683,  0.1758,  0.0612,  0.1008,  0.0521,  0.1378, -0.1505,
			                 0.1099, -0.0088,  0.1262, -0.0772, -0.1273, -0.0341,  0.1340, -0.0919,
			                 0.1005,  0.1687,  0.0555,  0.0395,  0.1722, -0.1073,  0.0085, -0.1426,
			                -0.0166, -0.0825,  0.0667, -0.1364,  0.1725, -0.0275,  0.0604,  0.1058])
			Loss decreased
			Epoch 0 took 0.25s NLL: 4.8158774376 Reg.: 0.0006202792 Distance: 26.5327911377 Patience: 10
			Loss decreased
			Epoch 1 took 0.21s NLL: 3.8416607380 Reg.: 0.0005192369 Distance: 18.1518039703 Patience: 10
			Loss decreased
			Epoch 2 took 0.15s NLL: 3.8330969810 Reg.: 0.0005083035 Distance: 0.4082585871 Patience: 10
			Epoch 3 took 0.08s NLL: 3.8330969810 Reg.: 0.0005083035 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592767715454
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.0660037994384766
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.3756,  -2.5037,  -2.1849,  -2.5985,  -2.8497,  -1.5558,  -2.7040,
			                 -2.5532,  -2.0474,  -2.8575,  -1.8097,  -2.9481, -15.9847,   7.3925,
			                 -7.9248,   6.8543])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0651, -0.0683,  0.1758,  0.0612,  0.1008,  0.0521,  0.1378, -0.1505,
			                 0.1099, -0.0088,  0.1262, -0.0772, -0.1273, -0.0341,  0.1340, -0.0919,
			                 0.1005,  0.1687,  0.0555,  0.0395,  0.1722, -0.1073,  0.0085, -0.1426,
			                -0.0166, -0.0825,  0.0667, -0.1364,  0.1725, -0.0275,  0.0604,  0.1058]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -3.838592767715454
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.0660037994384766
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.3756,  -2.5037,  -2.1849,  -2.5985,  -2.8497,  -1.5558,  -2.7040,
			                 -2.5532,  -2.0474,  -2.8575,  -1.8097,  -2.9481, -15.9847,   7.3925,
			                 -7.9248,   6.8543])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0651, -0.0683,  0.1758,  0.0612,  0.1008,  0.0521,  0.1378, -0.1505,
			                 0.1099, -0.0088,  0.1262, -0.0772, -0.1273, -0.0341,  0.1340, -0.0919,
			                 0.1005,  0.1687,  0.0555,  0.0395,  0.1722, -0.1073,  0.0085, -0.1426,
			                -0.0166, -0.0825,  0.0667, -0.1364,  0.1725, -0.0275,  0.0604,  0.1058])
			Loss decreased
			Epoch 0 took 0.18s NLL: 2.1588146687 Reg.: 0.0005069990 Distance: 2.2779147625 Patience: 10
			Loss decreased
			Epoch 1 took 0.12s NLL: 2.1588144302 Reg.: 0.0005069636 Distance: 0.0014253667 Patience: 10
			Epoch 2 took 0.12s NLL: 2.1588144302 Reg.: 0.0005069636 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.371734619140625
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.3948107957839966
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -inf
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.3793,  -2.6614,  -2.1526,  -3.1237,  -3.1763,  -0.9697,  -3.3507,
			                 -2.8204,  -1.5168,  -3.4740,  -1.5784,  -3.7478, -15.9778,   7.2960,
			                 -7.9213,   6.2861])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0651, -0.0683,  0.1758,  0.0612,  0.1008,  0.0521,  0.1378, -0.1505,
			                 0.1099, -0.0088,  0.1262, -0.0772, -0.1273, -0.0341,  0.1340, -0.0919,
			                 0.1005,  0.1687,  0.0555,  0.0395,  0.1722, -0.1073,  0.0085, -0.1426,
			                -0.0166, -0.0825,  0.0667, -0.1364,  0.1725, -0.0275,  0.0604,  0.1058]) 


### Training Mode 2: 1stPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→2ndContribution → 0thBoundUnsaturatedRound→1stPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→2ndContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	1stPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.9811720848083496
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -3.004249095916748
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -1.4191802740097046
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ -2.3793,  -2.6614,  -2.1526,  -3.1237,  -3.1763,  -0.9697,  -3.3507,
			                 -2.8204,  -1.5168,  -3.4740,  -1.5784,  -3.7478, -15.9778,   7.2960,
			                 -7.9213,   6.2861])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.0651, -0.0683,  0.1758,  0.0612,  0.1008,  0.0521,  0.1378, -0.1505,
			                 0.1099, -0.0088,  0.1262, -0.0772, -0.1273, -0.0341,  0.1340, -0.0919,
			                 0.1005,  0.1687,  0.0555,  0.0395,  0.1722, -0.1073,  0.0085, -0.1426,
			                -0.0166, -0.0825,  0.0667, -0.1364,  0.1725, -0.0275,  0.0604,  0.1058])
			Loss decreased
			Epoch 0 took 0.27s NLL: 1.9804953337 Reg.: 0.0005303289 Distance: 2.0527935028 Patience: 10
			Epoch 1 took 0.08s NLL: 1.9804953337 Reg.: 0.0005303289 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.9811720848083496
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -3.004249095916748
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -1.4191802740097046
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ -2.3793,  -2.6614,  -2.1526,  -3.1237,  -3.1763,  -0.9697,  -3.3507,
			                 -2.8204,  -1.5168,  -3.4740,  -1.5784,  -3.7478, -15.9778,   7.2960,
			                 -7.9213,   6.2861])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.1857, -0.3444,  0.3629, -0.2020, -0.5009,  0.3563, -0.1098,  0.1631,
			                -0.0885,  0.1477,  0.4785, -0.6192, -0.1001, -0.1449, -0.1302,  0.0244,
			                -0.6689,  0.6522,  0.2320, -0.0828,  0.2581, -0.3409,  0.4316, -0.6496,
			                -0.5675,  0.2927, -0.4064,  0.2810, -0.0013, -0.2528,  0.6537, -0.3200]) 

	2.	0thBoundUnsaturatedRound→1stPSAMMode.update_read_length(left_shift=1, right_shift=1)
	Greedy search terminated: left flank length of 1 exceeds max_left_flank_length of 0
	3.	1stPSAM.shift_heuristic()
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.9811720848083496
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -3.0042495727539062
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -1.4880682229995728
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ -2.3793,  -2.6614,  -2.1526,  -3.1237,  -3.1763,  -0.9697,  -3.3507,
			                 -2.8204,  -1.5168,  -3.4740,  -1.5784,  -3.7478, -15.9778,   7.2960,
			                 -7.9213,   6.2861])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-0.5009,  0.3563, -0.1098,  0.1631, -0.0885,  0.1477,  0.4785, -0.6192,
			                -0.1001, -0.1449, -0.1302,  0.0244, -0.6689,  0.6522,  0.2320, -0.0828,
			                 0.2581, -0.3409,  0.4316, -0.6496, -0.5675,  0.2927, -0.4064,  0.2810,
			                -0.0013, -0.2528,  0.6537, -0.3200,  0.1635, -0.0271,  0.1676, -0.0262])
			Epoch 0 took 0.17s NLL: 1.9804953337 Reg.: 0.0005305493 Distance: 2.0768170357 Patience: 9
			Epoch 1 took 0.03s NLL: 1.9804953337 Reg.: 0.0005305492 Distance: 0.0002038829 Patience: 8
			Epoch 2 took 0.02s NLL: 1.9804953337 Reg.: 0.0005305492 Distance: 0.0000000000 Patience: 7
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.9811720848083496
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -3.0042495727539062
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=False -1.4880682229995728
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ -2.3793,  -2.6614,  -2.1526,  -3.1237,  -3.1763,  -0.9697,  -3.3507,
			                 -2.8204,  -1.5168,  -3.4740,  -1.5784,  -3.7478, -15.9778,   7.2960,
			                 -7.9213,   6.2861])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-0.5009,  0.3563, -0.1098,  0.1631, -0.0885,  0.1477,  0.4785, -0.6192,
			                -0.1001, -0.1449, -0.1302,  0.0244, -0.6689,  0.6522,  0.2320, -0.0828,
			                 0.2581, -0.3409,  0.4316, -0.6496, -0.5675,  0.2927, -0.4064,  0.2810,
			                -0.0013, -0.2528,  0.6537, -0.3200,  0.1635, -0.0271,  0.1676, -0.0262]) 

	Update rejected
	4.	1stPSAM.update_footprint(left_shift=1, check_threshold=True, right_shift=1)
		0thBoundUnsaturatedRound→1stPSAMMode.update_read_length(left_shift=1, right_shift=1)
	Greedy search terminated: left flank length of 1 exceeds max_left_flank_length of 0
	5.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -3.9811720848083496
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -3.004249095916748
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=True -1.4191802740097046
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.3793,  -2.6614,  -2.1526,  -3.1237,  -3.1763,  -0.9697,  -3.3507,
			                 -2.8204,  -1.5168,  -3.4740,  -1.5784,  -3.7478, -15.9778,   7.2960,
			                 -7.9213,   6.2861])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-0.5009,  0.3563, -0.1098,  0.1631, -0.0885,  0.1477,  0.4785, -0.6192,
			                -0.1001, -0.1449, -0.1302,  0.0244, -0.6689,  0.6522,  0.2320, -0.0828,
			                 0.2581, -0.3409,  0.4316, -0.6496, -0.5675,  0.2927, -0.4064,  0.2810,
			                -0.0013, -0.2528,  0.6537, -0.3200,  0.1857, -0.3444,  0.3629, -0.2020])
			Loss decreased
			Epoch 0 took 0.31s NLL: 1.7502814531 Reg.: 0.0005710709 Distance: 6.2322702408 Patience: 10
			Loss decreased
			Epoch 1 took 0.25s NLL: 1.7463542223 Reg.: 0.0006016101 Distance: 2.5903508663 Patience: 10
			Loss decreased
			Epoch 2 took 0.18s NLL: 1.7461392879 Reg.: 0.0006327775 Distance: 2.4922413826 Patience: 10
			Loss decreased
			Epoch 3 took 0.42s NLL: 1.7273522615 Reg.: 0.0001490716 Distance: 17.9620418549 Patience: 10
			Epoch 4 took 0.18s NLL: 1.7273522615 Reg.: 0.0001490716 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.762444257736206
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -0.8027875423431396
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.2.log_activity grad=True -2.92703914642334
				rounds.0.aggregate.contributions.2.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.2.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-0.4369, -0.7006, -0.2337, -1.0320, -1.1873,  0.7399, -1.1919, -0.7643,
			                 0.1848, -1.3431,  0.2982, -1.5428, -2.9554,  1.3760, -1.3626,  0.5396])
				rounds.0.aggregate.contributions.2.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-0.8156, -0.5034, -0.4186, -0.9439, -0.9783,  0.4985, -0.8891, -1.3109,
			                 0.2381, -1.0693, -0.4585, -1.4392, -5.5464,  3.0814, -1.3039,  1.1302,
			                 1.8502, -1.3047,  2.1804, -5.4451, -1.9868,  0.4432, -1.8976,  0.7036,
			                -0.7532, -1.6783,  1.2875, -1.5046, -0.5635, -0.7655, -0.4472, -0.8879]) 

### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.02s NLL: 2.3551154137 Reg.: 0.0008383029 Distance: 0.1497132778 Patience: 10
			Epoch 1 took 0.01s NLL: 2.3551154137 Reg.: 0.0008383029 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.2291548252105713
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.21s NLL: 4.7663240433 Reg.: 0.0005333610 Distance: 26.4574508667 Patience: 10
			Loss decreased
			Epoch 1 took 0.21s NLL: 3.8355629444 Reg.: 0.0005493050 Distance: 15.6702899933 Patience: 10
			Loss decreased
			Epoch 2 took 0.13s NLL: 3.8330967426 Reg.: 0.0005511088 Distance: 0.1931290925 Patience: 10
			Epoch 3 took 0.06s NLL: 3.8330967426 Reg.: 0.0005511088 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5027,  -2.6301,  -2.3129,  -2.7268,  -2.9770,  -1.6831,  -2.8312,
			                 -2.6812,  -2.1765,  -2.9838,  -1.9369,  -3.0753, -16.1680,   7.7753,
			                 -9.0164,   7.2367]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5027,  -2.6301,  -2.3129,  -2.7268,  -2.9770,  -1.6831,  -2.8312,
			                 -2.6812,  -2.1765,  -2.9838,  -1.9369,  -3.0753, -16.1680,   7.7753,
			                 -9.0164,   7.2367])
			Loss decreased
			Epoch 0 took 0.16s NLL: 2.1588149071 Reg.: 0.0005497840 Distance: 2.2784261703 Patience: 10
			Loss decreased
			Epoch 1 took 0.03s NLL: 2.1588146687 Reg.: 0.0005497359 Distance: 0.0021469553 Patience: 10
			Loss decreased
			Epoch 2 took 0.04s NLL: 2.1588149071 Reg.: 0.0005490824 Distance: 0.0147448601 Patience: 10
			Epoch 3 took 0.31s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True nan
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True nan
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.17s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.3716564178466797
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.393871545791626
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5049,  -2.7862,  -2.2791,  -3.2498,  -3.3038,  -1.0959,  -3.4731,
			                 -2.9471,  -1.6438,  -3.5974,  -1.7047,  -3.8741, -16.1513,   7.6737,
			                 -9.0071,   6.6649]) 

### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.02s NLL: 2.3551154137 Reg.: 0.0008383029 Distance: 0.1497132778 Patience: 10
			Epoch 1 took 0.01s NLL: 2.3551154137 Reg.: 0.0008383029 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.2291548252105713
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.23s NLL: 4.7663240433 Reg.: 0.0005333610 Distance: 26.4574508667 Patience: 10
			Loss decreased
			Epoch 1 took 0.22s NLL: 3.8355629444 Reg.: 0.0005493050 Distance: 15.6702899933 Patience: 10
			Loss decreased
			Epoch 2 took 0.14s NLL: 3.8330967426 Reg.: 0.0005511088 Distance: 0.1931290925 Patience: 10
			Epoch 3 took 0.07s NLL: 3.8330967426 Reg.: 0.0005511088 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5027,  -2.6301,  -2.3129,  -2.7268,  -2.9770,  -1.6831,  -2.8312,
			                 -2.6812,  -2.1765,  -2.9838,  -1.9369,  -3.0753, -16.1680,   7.7753,
			                 -9.0164,   7.2367]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5027,  -2.6301,  -2.3129,  -2.7268,  -2.9770,  -1.6831,  -2.8312,
			                 -2.6812,  -2.1765,  -2.9838,  -1.9369,  -3.0753, -16.1680,   7.7753,
			                 -9.0164,   7.2367])
			Loss decreased
			Epoch 0 took 0.18s NLL: 2.1588149071 Reg.: 0.0005497840 Distance: 2.2784261703 Patience: 10
			Loss decreased
			Epoch 1 took 0.04s NLL: 2.1588146687 Reg.: 0.0005497359 Distance: 0.0021469553 Patience: 10
			Loss decreased
			Epoch 2 took 0.04s NLL: 2.1588149071 Reg.: 0.0005490824 Distance: 0.0147448601 Patience: 10
			Epoch 3 took 0.32s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True nan
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True nan
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.20s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.3716564178466797
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.393871545791626
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5049,  -2.7862,  -2.2791,  -3.2498,  -3.3038,  -1.0959,  -3.4731,
			                 -2.9471,  -1.6438,  -3.5974,  -1.7047,  -3.8741, -16.1513,   7.6737,
			                 -9.0071,   6.6649]) 

### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.14s NLL: 2.3551154137 Reg.: 0.0008383029 Distance: 0.1497132778 Patience: 10
			Epoch 1 took 0.01s NLL: 2.3551154137 Reg.: 0.0008383029 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.2291548252105713
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.22s NLL: 4.7663240433 Reg.: 0.0005333610 Distance: 26.4574508667 Patience: 10
			Loss decreased
			Epoch 1 took 0.17s NLL: 3.8355629444 Reg.: 0.0005493050 Distance: 15.6702899933 Patience: 10
			Loss decreased
			Epoch 2 took 0.11s NLL: 3.8330967426 Reg.: 0.0005511088 Distance: 0.1931290925 Patience: 10
			Epoch 3 took 0.06s NLL: 3.8330967426 Reg.: 0.0005511088 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5027,  -2.6301,  -2.3129,  -2.7268,  -2.9770,  -1.6831,  -2.8312,
			                 -2.6812,  -2.1765,  -2.9838,  -1.9369,  -3.0753, -16.1680,   7.7753,
			                 -9.0164,   7.2367]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5027,  -2.6301,  -2.3129,  -2.7268,  -2.9770,  -1.6831,  -2.8312,
			                 -2.6812,  -2.1765,  -2.9838,  -1.9369,  -3.0753, -16.1680,   7.7753,
			                 -9.0164,   7.2367])
			Loss decreased
			Epoch 0 took 0.15s NLL: 2.1588149071 Reg.: 0.0005497840 Distance: 2.2784261703 Patience: 10
			Loss decreased
			Epoch 1 took 0.03s NLL: 2.1588146687 Reg.: 0.0005497359 Distance: 0.0021469553 Patience: 10
			Loss decreased
			Epoch 2 took 0.04s NLL: 2.1588149071 Reg.: 0.0005490824 Distance: 0.0147448601 Patience: 10
			Epoch 3 took 0.30s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True nan
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True nan
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.17s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.3716564178466797
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.393871545791626
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5049,  -2.7862,  -2.2791,  -3.2498,  -3.3038,  -1.0959,  -3.4731,
			                 -2.9471,  -1.6438,  -3.5974,  -1.7047,  -3.8741, -16.1513,   7.6737,
			                 -9.0071,   6.6649]) 

### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.03s NLL: 2.3551154137 Reg.: 0.0008383029 Distance: 0.1497132778 Patience: 10
			Epoch 1 took 0.01s NLL: 2.3551154137 Reg.: 0.0008383029 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.2291548252105713
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.21s NLL: 4.7663240433 Reg.: 0.0005333610 Distance: 26.4574508667 Patience: 10
			Loss decreased
			Epoch 1 took 0.19s NLL: 3.8355629444 Reg.: 0.0005493050 Distance: 15.6702899933 Patience: 10
			Loss decreased
			Epoch 2 took 0.11s NLL: 3.8330967426 Reg.: 0.0005511088 Distance: 0.1931290925 Patience: 10
			Epoch 3 took 0.06s NLL: 3.8330967426 Reg.: 0.0005511088 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5027,  -2.6301,  -2.3129,  -2.7268,  -2.9770,  -1.6831,  -2.8312,
			                 -2.6812,  -2.1765,  -2.9838,  -1.9369,  -3.0753, -16.1680,   7.7753,
			                 -9.0164,   7.2367]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5027,  -2.6301,  -2.3129,  -2.7268,  -2.9770,  -1.6831,  -2.8312,
			                 -2.6812,  -2.1765,  -2.9838,  -1.9369,  -3.0753, -16.1680,   7.7753,
			                 -9.0164,   7.2367])
			Loss decreased
			Epoch 0 took 0.15s NLL: 2.1588149071 Reg.: 0.0005497840 Distance: 2.2784261703 Patience: 10
			Loss decreased
			Epoch 1 took 0.03s NLL: 2.1588146687 Reg.: 0.0005497359 Distance: 0.0021469553 Patience: 10
			Loss decreased
			Epoch 2 took 0.04s NLL: 2.1588149071 Reg.: 0.0005490824 Distance: 0.0147448601 Patience: 10
			Epoch 3 took 0.31s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True nan
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True nan
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.18s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.3716564178466797
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.393871545791626
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5049,  -2.7862,  -2.2791,  -3.2498,  -3.3038,  -1.0959,  -3.4731,
			                 -2.9471,  -1.6438,  -3.5974,  -1.7047,  -3.8741, -16.1513,   7.6737,
			                 -9.0071,   6.6649]) 

### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.02s NLL: 2.3551154137 Reg.: 0.0008383029 Distance: 0.1497132778 Patience: 10
			Epoch 1 took 0.01s NLL: 2.3551154137 Reg.: 0.0008383029 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.2291548252105713
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -5.8926, 17.6777, -5.8926, -5.8926,
			                17.6777, -5.8926, -5.8926, -5.8926,  0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.18s NLL: 4.7663240433 Reg.: 0.0005333610 Distance: 26.4574508667 Patience: 10
			Loss decreased
			Epoch 1 took 0.17s NLL: 3.8355629444 Reg.: 0.0005493050 Distance: 15.6702899933 Patience: 10
			Loss decreased
			Epoch 2 took 0.12s NLL: 3.8330967426 Reg.: 0.0005511088 Distance: 0.1931290925 Patience: 10
			Epoch 3 took 0.05s NLL: 3.8330967426 Reg.: 0.0005511088 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5027,  -2.6301,  -2.3129,  -2.7268,  -2.9770,  -1.6831,  -2.8312,
			                 -2.6812,  -2.1765,  -2.9838,  -1.9369,  -3.0753, -16.1680,   7.7753,
			                 -9.0164,   7.2367]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.0660033226013184
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5027,  -2.6301,  -2.3129,  -2.7268,  -2.9770,  -1.6831,  -2.8312,
			                 -2.6812,  -2.1765,  -2.9838,  -1.9369,  -3.0753, -16.1680,   7.7753,
			                 -9.0164,   7.2367])
			Loss decreased
			Epoch 0 took 0.14s NLL: 2.1588149071 Reg.: 0.0005497840 Distance: 2.2784261703 Patience: 10
			Loss decreased
			Epoch 1 took 0.03s NLL: 2.1588146687 Reg.: 0.0005497359 Distance: 0.0021469553 Patience: 10
			Loss decreased
			Epoch 2 took 0.04s NLL: 2.1588149071 Reg.: 0.0005490824 Distance: 0.0147448601 Patience: 10
			Epoch 3 took 0.27s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True nan
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True nan
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.18s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.3716564178466797
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.393871545791626
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -2.5049,  -2.7862,  -2.2791,  -3.2498,  -3.3038,  -1.0959,  -3.4731,
			                 -2.9471,  -1.6438,  -3.5974,  -1.7047,  -3.8741, -16.1513,   7.6737,
			                 -9.0071,   6.6649]) 

### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-6.8041, 20.4124, -6.8041, -6.8041, 20.4124, -6.8041, -6.8041, -6.8041,
			                 0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.02s NLL: 2.3551154137 Reg.: 0.0011160863 Distance: 0.1497132778 Patience: 10
			Epoch 1 took 0.00s NLL: 2.3551154137 Reg.: 0.0011160863 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.2291548252105713
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([-6.8041, 20.4124, -6.8041, -6.8041, 20.4124, -6.8041, -6.8041, -6.8041,
			                 0.0000,  0.0000,  0.0000,  0.0000]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -2.164616346359253
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-6.8041, 20.4124, -6.8041, -6.8041, 20.4124, -6.8041, -6.8041, -6.8041,
			                 0.0000,  0.0000,  0.0000,  0.0000])
			Loss decreased
			Epoch 0 took 0.18s NLL: 4.4673237801 Reg.: 0.0006883453 Distance: 33.2922973633 Patience: 10
			Loss decreased
			Epoch 1 took 0.21s NLL: 4.4149351120 Reg.: 0.0005839177 Distance: 5.3431334496 Patience: 10
			Epoch 2 took 0.06s NLL: 4.4149351120 Reg.: 0.0005839177 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -2.164616346359253
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -5.1005,  -3.1218,  -5.5349,  -5.5515,   6.3825,  -8.1349,  -9.2349,
			                 -8.3214, -13.7946,  -0.2001,  -3.4915,  -1.8224]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -3.838592290878296
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -2.164616346359253
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -5.1005,  -3.1218,  -5.5349,  -5.5515,   6.3825,  -8.1349,  -9.2349,
			                 -8.3214, -13.7946,  -0.2001,  -3.4915,  -1.8224])
			Loss decreased
			Epoch 0 took 0.15s NLL: 2.1874263287 Reg.: 0.0005898992 Distance: 2.5409862995 Patience: 10
			Epoch 1 took 0.02s NLL: 2.1874263287 Reg.: 0.0005898713 Distance: 0.0018561765 Patience: 9
			Loss decreased
			Epoch 2 took 0.03s NLL: 2.1874263287 Reg.: 0.0005897043 Distance: 0.0061959499 Patience: 10
			Epoch 3 took 0.28s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True nan
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True nan
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.17s NLL: nan Reg.: 0.0000000000 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.2991316318511963
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -2.486506223678589
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0., 0., 0.],
			                 [0., 0., 0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -5.0085,  -2.4780,  -6.2402,  -6.2104,   5.7211,  -8.1237,  -9.2243,
			                 -8.3103, -13.7807,   0.4809,  -4.8120,  -1.8253]) 

