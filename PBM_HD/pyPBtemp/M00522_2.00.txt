### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
			                  0.0000,  -5.8926,  -5.8926,  -5.8926,  17.6777,   5.8926, -17.6777,
			                  5.8926,   5.8926,  17.6777,  -5.8926,  -5.8926,  -5.8926, -10.2062,
			                 10.2062, -10.2062,  10.2062,   0.0000,   0.0000,   0.0000,   0.0000,
			                  0.0000,   0.0000,   0.0000,   0.0000])
			Loss decreased
			Epoch 0 took 0.02s NLL: 1.6006585360 Reg.: 0.0016731120 Distance: 0.4592256546 Patience: 10
			Epoch 1 took 0.01s NLL: 1.6006585360 Reg.: 0.0016731120 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.5386672019958496
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
			                  0.0000,  -5.8926,  -5.8926,  -5.8926,  17.6777,   5.8926, -17.6777,
			                  5.8926,   5.8926,  17.6777,  -5.8926,  -5.8926,  -5.8926, -10.2062,
			                 10.2062, -10.2062,  10.2062,   0.0000,   0.0000,   0.0000,   0.0000,
			                  0.0000,   0.0000,   0.0000,   0.0000]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.148104667663574
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.375516414642334
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
			                  0.0000,  -5.8926,  -5.8926,  -5.8926,  17.6777,   5.8926, -17.6777,
			                  5.8926,   5.8926,  17.6777,  -5.8926,  -5.8926,  -5.8926, -10.2062,
			                 10.2062, -10.2062,  10.2062,   0.0000,   0.0000,   0.0000,   0.0000,
			                  0.0000,   0.0000,   0.0000,   0.0000])
			Loss decreased
			Epoch 0 took 0.23s NLL: 3.3117628098 Reg.: 0.0007337028 Distance: 27.9608478546 Patience: 10
			Loss decreased
			Epoch 1 took 0.21s NLL: 2.0773382187 Reg.: 0.0006652477 Distance: 6.5338563919 Patience: 10
			Loss decreased
			Epoch 2 took 0.11s NLL: 2.0452637672 Reg.: 0.0006637074 Distance: 0.5915445089 Patience: 10
			Epoch 3 took 0.02s NLL: 2.0452637672 Reg.: 0.0006636913 Distance: 0.0016293396 Patience: 9
			Loss decreased
			Epoch 4 took 0.04s NLL: 2.0452635288 Reg.: 0.0006635233 Distance: 0.0037932540 Patience: 10
			Epoch 5 took 0.02s NLL: 2.0452637672 Reg.: 0.0006631957 Distance: 0.0065712566 Patience: 9
			Loss decreased
			Epoch 6 took 0.21s NLL: 1.0606191158 Reg.: 0.0000272022 Distance: 24.0055007935 Patience: 10
			Loss decreased
			Epoch 7 took 0.22s NLL: 1.0091627836 Reg.: 0.0000299863 Distance: 1.6685018539 Patience: 10
			Loss decreased
			Epoch 8 took 0.12s NLL: 1.0072003603 Reg.: 0.0000302629 Distance: 0.3796469867 Patience: 10
			Loss decreased
			Epoch 9 took 0.04s NLL: 1.0072002411 Reg.: 0.0000302617 Distance: 0.0007769032 Patience: 10
			Epoch 10 took 0.02s NLL: 1.0072002411 Reg.: 0.0000302617 Distance: 0.0003156465 Patience: 9
			Epoch 11 took 0.02s NLL: 1.0072002411 Reg.: 0.0000302617 Distance: 0.0001521461 Patience: 8
			Epoch 12 took 0.01s NLL: 1.0072002411 Reg.: 0.0000302617 Distance: 0.0000000000 Patience: 7
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.148104667663574
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.375516414642334
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.6062, -0.7693, -0.8782,  0.3759,  0.7132, -1.0796, -1.1149,  0.8148,
			                 0.4766, -1.0084, -0.8786,  0.7459,  0.4531, -1.0137, -0.5022,  0.3990,
			                 0.2866, -0.7644, -0.3726,  0.1886, -0.0772, -0.4513, -0.2860,  0.1512,
			                -0.1028, -0.2643, -0.2047, -0.0913,  0.0843, -0.3123, -0.2823, -0.1527]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -4.148104667663574
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.375516414642334
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.6062, -0.7693, -0.8782,  0.3759,  0.7132, -1.0796, -1.1149,  0.8148,
			                 0.4766, -1.0084, -0.8786,  0.7459,  0.4531, -1.0137, -0.5022,  0.3990,
			                 0.2866, -0.7644, -0.3726,  0.1886, -0.0772, -0.4513, -0.2860,  0.1512,
			                -0.1028, -0.2643, -0.2047, -0.0913,  0.0843, -0.3123, -0.2823, -0.1527])
			Loss decreased
			Epoch 0 took 0.26s NLL: 1.0056697130 Reg.: 0.0000316013 Distance: 0.4412966669 Patience: 10
			Epoch 1 took 0.02s NLL: 1.0056697130 Reg.: 0.0000316012 Distance: 0.0005776279 Patience: 9
			Loss decreased
			Epoch 2 took 0.05s NLL: 1.0056695938 Reg.: 0.0000316020 Distance: 0.0001568570 Patience: 10
			Epoch 3 took 0.04s NLL: 1.0056695938 Reg.: 0.0000316020 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -4.505771160125732
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.3064228296279907
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ 0.5818, -0.7214, -0.8184,  0.3614,  0.6600, -1.0045, -1.0171,  0.7640,
			                 0.4423, -0.9354, -0.8048,  0.7023,  0.4282, -0.9394, -0.4588,  0.3750,
			                 0.2698, -0.7038, -0.3336,  0.1746, -0.0802, -0.4100, -0.2530,  0.1488,
			                -0.1016, -0.2302, -0.1791, -0.0835,  0.0844, -0.2780, -0.2509, -0.1495]) 

