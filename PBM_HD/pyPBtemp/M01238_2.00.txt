### Regularization:
	 L1 Lambda: 0
	 L2 Lambda: 1e-06
	 Pseudocount: 20
	 Exponential Bound: 40
	 Excluded Reg.: frozenset()
	 Eq. Contribution: False
	 Weights: [1.0]

### Binding Components:
	 Mode 0: (NSNonSpecific,)
		0thBoundUnsaturatedRound→Aggregate→0thContribution
	 Mode 1: (0thPSAM,)
		0thBoundUnsaturatedRound→Aggregate→1stContribution

### Tables:
	Table: 0
		Maximum Variable Length: 8
		Left Flank Length: 0
		Right Flank Length: 0

### Training Mode 0: NSNonSpecific
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→0thContribution → 0thBoundUnsaturatedRound→NSNonSpecificMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→0thContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.079441547393799
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
			                  0.0000,  -5.8926,  -5.8926,  -5.8926,  17.6777,   5.8926, -17.6777,
			                  5.8926,   5.8926,  17.6777,  -5.8926,  -5.8926,  -5.8926, -10.2062,
			                 10.2062, -10.2062,  10.2062,   0.0000,   0.0000,   0.0000,   0.0000,
			                  0.0000,   0.0000,   0.0000,   0.0000])
			Loss decreased
			Epoch 0 took 0.02s NLL: 1.4039094448 Reg.: 0.0016734374 Distance: 0.5225160122 Patience: 10
			Epoch 1 took 0.01s NLL: 1.4039094448 Reg.: 0.0016734374 Distance: 0.0000000000 Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.6019575595855713
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -inf
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=False
					tensor([  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
			                  0.0000,  -5.8926,  -5.8926,  -5.8926,  17.6777,   5.8926, -17.6777,
			                  5.8926,   5.8926,  17.6777,  -5.8926,  -5.8926,  -5.8926, -10.2062,
			                 10.2062, -10.2062,  10.2062,   0.0000,   0.0000,   0.0000,   0.0000,
			                  0.0000,   0.0000,   0.0000,   0.0000]) 


### Training Mode 1: 0thPSAM
	MultiExperimentLogMSELoss → 0thBoundUnsaturatedRound → 0thBoundUnsaturatedRound→Aggregate → 0thBoundUnsaturatedRound→Aggregate→1stContribution → 0thBoundUnsaturatedRound→0thPSAMMode
	0.	MultiExperimentLogMSELoss.freeze()
		0thBoundUnsaturatedRound→Aggregate.activity_heuristic(contribution=0thBoundUnsaturatedRound→Aggregate→1stContribution)
		0thBoundUnsaturatedRound.unfreeze(parameter=depth)
	1.	0thPSAM.unfreeze(parameter=monomer)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.211394786834717
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.4388067722320557
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,
			                  0.0000,  -5.8926,  -5.8926,  -5.8926,  17.6777,   5.8926, -17.6777,
			                  5.8926,   5.8926,  17.6777,  -5.8926,  -5.8926,  -5.8926, -10.2062,
			                 10.2062, -10.2062,  10.2062,   0.0000,   0.0000,   0.0000,   0.0000,
			                  0.0000,   0.0000,   0.0000,   0.0000])
			Loss decreased
			Epoch 0 took 0.37s NLL: 3.4100449085 Reg.: 0.0005382022 Distance: 28.6012668610 Patience: 10
			Epoch 1 took 0.19s NLL: nan Reg.: 0.0000198060 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.211394786834717
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.4388067722320557
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
			                nan, nan, nan, nan, nan, nan, nan, nan])
			Epoch 0 took 0.20s NLL: nan Reg.: 0.0000198060 Distance: nan Patience: 9
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=False -4.211394786834717
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=False -1.4388067722320557
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -1.9021,  -2.0154,  -1.8825,  -1.9466,  -1.9537,  -1.9194,  -1.9179,
			                 -1.9556,  -3.8489,  -3.0420,  -4.0154,   3.1598,   1.8580, -13.6959,
			                  2.6363,   1.4550,  -1.1794,  -3.6019,  -1.9538,  -1.0115,  -8.5047,
			                  4.9571,  -8.5163,   4.3172,  -1.7447,  -2.4161,  -1.8009,  -1.7849,
			                 -1.5851,  -2.5403,  -1.8277,  -1.7935]) 

	2.	MultiExperimentLogMSELoss.unfreeze(parameter=all)
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -4.211394786834717
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -1.4388067722320557
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([ -1.9021,  -2.0154,  -1.8825,  -1.9466,  -1.9537,  -1.9194,  -1.9179,
			                 -1.9556,  -3.8489,  -3.0420,  -4.0154,   3.1598,   1.8580, -13.6959,
			                  2.6363,   1.4550,  -1.1794,  -3.6019,  -1.9538,  -1.0115,  -8.5047,
			                  4.9571,  -8.5163,   4.3172,  -1.7447,  -2.4161,  -1.8009,  -1.7849,
			                 -1.5851,  -2.5403,  -1.8277,  -1.7935])
			Loss decreased
			Epoch 0 took 0.19s NLL: 1.3144013882 Reg.: 0.0006072521 Distance: 9.6430101395 Patience: 10
			Loss decreased
			Epoch 1 took 0.20s NLL: 1.3100544214 Reg.: 0.0005743482 Distance: 2.4189360142 Patience: 10
			Loss decreased
			Epoch 2 took 0.22s NLL: 1.3095600605 Reg.: 0.0005129875 Distance: 6.5154452324 Patience: 10
			Loss decreased
			Epoch 3 took 0.19s NLL: 1.3095406294 Reg.: 0.0003297332 Distance: 10.6640110016 Patience: 10
			Loss decreased
			Epoch 4 took 0.16s NLL: 1.3093870878 Reg.: 0.0002439810 Distance: 6.0021729469 Patience: 10
			Loss decreased
			Epoch 5 took 0.22s NLL: 1.3092552423 Reg.: 0.0001529862 Distance: 5.8528370857 Patience: 10
			Epoch 6 took 0.02s NLL: 1.3092548847 Reg.: 0.0001532883 Distance: 0.0148149319 Patience: 9
			Loss decreased
			Epoch 7 took 0.11s NLL: 1.3092105389 Reg.: 0.0001762855 Distance: 1.4004226923 Patience: 10
			Epoch 8 took 0.02s NLL: 1.3092108965 Reg.: 0.0001759549 Distance: 0.0283489283 Patience: 9
			Epoch 9 took 0.02s NLL: 1.3092108965 Reg.: 0.0001759474 Distance: 0.0044759065 Patience: 8
			Epoch 10 took 0.02s NLL: 1.3092108965 Reg.: 0.0001759753 Distance: 0.0037657130 Patience: 7
			Epoch 11 took 0.02s NLL: 1.3092108965 Reg.: 0.0001759753 Distance: 0.0000000000 Patience: 6
				rounds.0.log_depth grad=False 0.0
				rounds.0.aggregate.log_target_concentration grad=False 0.0
				rounds.0.aggregate.contributions.0.log_activity grad=True -2.699699878692627
				rounds.0.aggregate.contributions.0.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.0.binding.layers.0.log_posbias grad=False tensor([[[0.]]])
				rounds.0.aggregate.contributions.1.log_activity grad=True -3.462864398956299
				rounds.0.aggregate.contributions.1.binding.log_hill grad=False 0.0
				rounds.0.aggregate.contributions.1.binding.layers.0.log_posbias grad=False
					tensor([[[0.],
			                 [0.]]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.bias grad=False tensor([[0.]])
				rounds.0.aggregate.contributions.1.binding.layers.0.layer_spec.betas-monomer grad=True
					tensor([-1.0228, -1.0135, -0.9778, -1.2014, -0.6859, -0.9445, -1.2919, -1.2931,
			                -1.5917, -0.9464, -1.7470,  0.0694, -0.8747, -1.0689,  2.5871, -4.8591,
			                 2.7533, -4.8024, -4.9834,  2.8170, -5.1304,  2.5873, -1.1294, -0.5431,
			                 0.0251, -1.7214, -0.9543, -1.5651, -1.3544, -1.3387, -0.8676, -0.6549]) 

